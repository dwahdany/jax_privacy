{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhEsOXuFKCnX"
      },
      "source": [
        "This colab loads canary observations and computes an estimated epsilon.\n",
        "\n",
        "--\n",
        "\n",
        "Copyright 2024 DeepMind Technologies Limited.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
        "\n",
        "http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3EVkElUPWH5G"
      },
      "outputs": [],
      "source": [
        "# @title Imports\n",
        "\n",
        "import functools\n",
        "import json\n",
        "\n",
        "import dp_accounting\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy\n",
        "import math\n",
        "import jax\n",
        "\n",
        "from jax_privacy.auditing import canary_score_auditor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27C52vlnAg1w"
      },
      "source": [
        "# Audit using gradient canaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mgrz9JLEWsXn"
      },
      "outputs": [],
      "source": [
        "# @title Load auditing observations.\n",
        "\n",
        "TRAIN_METRICS_PATH = ''  # @param {type: 'string'}\n",
        "with open(TRAIN_METRICS_PATH, 'r') as f:\n",
        "  train_metrics = json.load(f)\n",
        "\n",
        "CONFIGS_PATH = ''  # @param {type: 'string'}\n",
        "with open(CONFIGS_PATH, 'r') as f:\n",
        "  config = json.load(f)\n",
        "\n",
        "# Separate observations into in and out of training canaries.\n",
        "out_canary = []\n",
        "in_canary = []\n",
        "for i in range(len(train_metrics['canary_count'])):\n",
        "  # 'canary_count' is zero if not in training.\n",
        "  if not train_metrics['canary_count'][i]:\n",
        "    out_canary.append(train_metrics['canary_dot_prod'][i])\n",
        "  else:\n",
        "    in_canary.append(train_metrics['canary_dot_prod'][i])\n",
        "out_canary, in_canary = np.array(out_canary), np.array(in_canary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BoNerXTa2kOU"
      },
      "outputs": [],
      "source": [
        "# @title Extract config details\n",
        "batch_size = config['training']['batch_size']['total']\n",
        "num_samples = config['data_train']['config']['num_samples']\n",
        "noise_multiplier = config['training']['dp']['algorithm']['noise_multiplier']\n",
        "nom_epsilon = config['training']['dp']['auto_tune_target_epsilon']\n",
        "clipping_norm = config['training']['dp']['clipping_norm']\n",
        "target_delta = config['training']['dp']['delta']\n",
        "num_steps = len(out_canary) + len(in_canary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bDCLAagd6mQ"
      },
      "outputs": [],
      "source": [
        "# @title Define functions to convert observations to epsilons\n",
        "\n",
        "\n",
        "def pld_epsilon(\n",
        "    sampling_probability: float,\n",
        "    noise_multiplier: float,\n",
        "    steps: int,\n",
        "    delta: float = 1e-5,\n",
        ") -\u003e float:\n",
        "  \"\"\"Calculates the epsilon value for a differentially private mechanism.\n",
        "\n",
        "  This function computes the epsilon value for a differentially private\n",
        "  mechanism\n",
        "  that uses Poisson sampling and Gaussian noise, using the Privacy Loss\n",
        "  Distribution (PLD) accountant.\n",
        "\n",
        "  Args:\n",
        "    sampling_probability: The probability of sampling an example from the\n",
        "      dataset.\n",
        "    noise_multiplier: The noise multiplier for the Gaussian mechanism.\n",
        "    steps: The number of steps the mechanism is applied.\n",
        "    delta: The desired delta value for the (epsilon, delta)-differential privacy\n",
        "      guarantee.\n",
        "\n",
        "  Returns:\n",
        "    The epsilon value for the given parameters.\n",
        "  \"\"\"\n",
        "  event = dp_accounting.dp_event.PoissonSampledDpEvent(\n",
        "      sampling_probability,\n",
        "      event=dp_accounting.dp_event.GaussianDpEvent(noise_multiplier),\n",
        "  )\n",
        "  pld_accountant = dp_accounting.pld.PLDAccountant()\n",
        "  pld_accountant.compose(event, steps)\n",
        "  epsilon = pld_accountant.get_epsilon(delta)\n",
        "  return epsilon\n",
        "\n",
        "\n",
        "def privacy_boundary_gdp(thr: float, mu: float = 1.0) -\u003e tuple[float, float]:\n",
        "  \"\"\"Get GDP tradeoff metrics for a given threshold and mu.\"\"\"\n",
        "  fnr = scipy.stats.norm.cdf(thr)\n",
        "  fpr = 1 - scipy.stats.norm.cdf(thr - mu)\n",
        "  return fnr, fpr\n",
        "\n",
        "\n",
        "def find_mu_gdp(eps: float, delta: float = 1e-5) -\u003e float:\n",
        "  \"\"\"Get mu GDP parameter for a given epsilon and delta.\"\"\"\n",
        "  dp_approx = (\n",
        "      lambda best_mu: (\n",
        "          scipy.stats.norm.cdf(-(eps / best_mu) + best_mu / 2)\n",
        "          - np.exp(eps) * scipy.stats.norm.cdf(-(eps / best_mu) - best_mu / 2)\n",
        "      )\n",
        "      - delta\n",
        "  )\n",
        "  best_mu = scipy.optimize.bisect(dp_approx, 0.01, 10, xtol=1e-9)\n",
        "  return best_mu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pyqwh6XVA7Ig"
      },
      "outputs": [],
      "source": [
        "# @title Get epsilon estimate and nominal upper bound.\n",
        "\n",
        "auditor = canary_score_auditor.CanaryScoreAuditor(\n",
        "    in_canary_scores=in_canary,\n",
        "    out_canary_scores=out_canary\n",
        "    )\n",
        "\n",
        "# We find the epsilon privacy parameter for the canary.\n",
        "nom_canary_epsilon = pld_epsilon(\n",
        "    sampling_probability=1.0,\n",
        "    noise_multiplier=noise_multiplier,\n",
        "    steps=1,\n",
        "    delta=target_delta,\n",
        ")\n",
        "\n",
        "# Get epsilon lower bound.\n",
        "eps_lb = auditor.epsilon_lower_bound(\n",
        "    alpha=0.05,\n",
        "    delta=1e-5)\n",
        "\n",
        "# Get epsilon lower bound from GDP analysis.\n",
        "eps_lb_from_gdp = auditor.epsilon_from_gdp(\n",
        "    alpha=0.05,\n",
        "    delta=1e-5)\n",
        "\n",
        "\n",
        "# We turn this into a general estimate for epsilon by estimating the noise multiplier and then composing with an accountant.\n",
        "estimate_noise_multiplier_fn = (\n",
        "    lambda nm: eps_lb_from_gdp\n",
        "    - pld_epsilon(\n",
        "        sampling_probability=1.0,\n",
        "        noise_multiplier=nm,\n",
        "        steps=1,\n",
        "        delta=target_delta,\n",
        "    )\n",
        ")\n",
        "noise_multiplier_estimate = scipy.optimize.bisect(\n",
        "    estimate_noise_multiplier_fn, 0, 10, xtol=0.01\n",
        ")\n",
        "epsilon_estimate = pld_epsilon(\n",
        "    sampling_probability=batch_size / num_samples,\n",
        "    noise_multiplier=noise_multiplier_estimate,\n",
        "    steps=num_steps,\n",
        "    delta=target_delta,\n",
        ")\n",
        "\n",
        "# Plot a histogram of observations.\n",
        "plt.hist(out_canary, alpha=0.3, label='Canary out')\n",
        "plt.hist(in_canary, alpha=0.3, label='Canary in')\n",
        "plt.xlabel('Observation')\n",
        "plt.title(\n",
        "    f'Canary epsilon: {nom_canary_epsilon:.3f} Canary estimate from GDP:'\n",
        "    f' {eps_lb_from_gdp:.3f} Canary estimate: {eps_lb:.3f}\\n'\n",
        "    f' Epsilon: {nom_epsilon:.3f} Estimate from GDP: {epsilon_estimate:.3f}'\n",
        ")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBPp3CnsIM22"
      },
      "outputs": [],
      "source": [
        "# @title Plot trade-off curve (observed and estimated).\n",
        "\n",
        "# Boundaries for thresholding.\n",
        "min_thr = min(min(out_canary), min(in_canary))\n",
        "max_thr = max(max(out_canary), max(in_canary))\n",
        "num_thresholds_to_try = 1000  # @param {type: 'integer'}\n",
        "\n",
        "# Find mu and corresponding fpr and fnr.\n",
        "best_mu = find_mu_gdp(eps_lb_from_gdp, delta=target_delta)\n",
        "met = list(\n",
        "    map(\n",
        "        functools.partial(privacy_boundary_gdp, mu=best_mu),\n",
        "        np.linspace(min_thr, max_thr, num_thresholds_to_try),\n",
        "    )\n",
        ")\n",
        "mu_fnrs, mu_fprs = zip(*met)\n",
        "mu_fnrs, mu_fprs = np.array(mu_fnrs), np.array(mu_fprs)\n",
        "\n",
        "# Plot observed rates vs estimated rates.\n",
        "tns, fns = canary_score_auditor._get_tn_fn_counts(in_canary, out_canary)\n",
        "fps = len(in_canary) - tns\n",
        "fnrs = fns / len(in_canary)\n",
        "fprs = fps / len(out_canary)\n",
        "\n",
        "plt.plot(fprs, fnrs, label='Observation', linestyle='--')\n",
        "plt.plot(\n",
        "    np.linspace(0, 1, 50),\n",
        "    1 - np.linspace(0, 1, 50),\n",
        "    color='black',\n",
        "    linestyle='--',\n",
        "    alpha=0.1,\n",
        ")\n",
        "plt.plot(mu_fprs, mu_fnrs, color='g', alpha=0.4)\n",
        "plt.plot(\n",
        "    1 - mu_fprs, 1 - mu_fnrs, label=f'{best_mu:.2f}-GDP', color='g', alpha=0.4\n",
        ")\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('FNR')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nu1oHF0GAiNh"
      },
      "source": [
        "# Audit using input canaries\n",
        "\n",
        "Using techniques from Thomas Steinke, Milad Nasr, and Matthew Jagielski. \"Privacy auditing with one (1) training run.\" Advances in Neural Information Processing Systems 36 (2023): 49268-49280. https://arxiv.org/abs/2305.08846"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5wE4jWVAlfb"
      },
      "outputs": [],
      "source": [
        "# @title Load auditing observations.\n",
        "\n",
        "INPUT_CANARY_METRICS_PATH = ''  # @param {type: 'string'}\n",
        "with open(INPUT_CANARY_METRICS_PATH, 'r') as f:\n",
        "  input_canary_metrics = json.load(f)\n",
        "\n",
        "INPUT_CANARY_CONFIGS_PATH = ''  # @param {type: 'string'}\n",
        "with open(INPUT_CANARY_CONFIGS_PATH, 'r') as f:\n",
        "  input_canary_config = json.load(f)\n",
        "\n",
        "target_delta = input_canary_config['training']['dp']['delta']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtOn9qEgy8q9"
      },
      "outputs": [],
      "source": [
        "#@title Methods for computing epsilon (Appendix D of https://arxiv.org/abs/2305.08846)\n",
        "\n",
        "def p_value_DP_audit(m, r, v, eps, delta):\n",
        "    \"\"\"\n",
        "    Calculates the p-value for a DP audit.\n",
        "\n",
        "    Args:\n",
        "        m: Number of examples, each included independently with probability 0.5.\n",
        "        r: Number of guesses (excluding abstentions).\n",
        "        v: Number of correct guesses by auditor.\n",
        "        eps: DP guarantee of null hypothesis.\n",
        "        delta: DP guarantee of null hypothesis.\n",
        "\n",
        "    Returns:\n",
        "        p: The p-value, probability of \u003e= v correct guesses under null hypothesis.\n",
        "    \"\"\"\n",
        "    assert 0 \u003c= v \u003c= r \u003c= m\n",
        "    assert eps \u003e= 0\n",
        "    assert 0 \u003c= delta \u003c= 1\n",
        "\n",
        "    q = 1 / (1 + math.exp(-eps))  # accuracy of eps-DP randomized response\n",
        "    beta = scipy.stats.binom.sf(v - 1, r, q)  # P[Binomial(r, q) \u003e= v]\n",
        "\n",
        "    alpha = 0\n",
        "    sum_val = 0  # P[v \u003e Binomial(r, q) \u003e= vi]\n",
        "\n",
        "    for i in range(1, v + 1):\n",
        "      sum_val += scipy.stats.binom.pmf(v-i, r, q)\n",
        "\n",
        "      if sum_val \u003e i * alpha:\n",
        "          alpha = sum_val / i\n",
        "\n",
        "    p = beta + alpha * delta * 2 * m\n",
        "    return min(p, 1)\n",
        "\n",
        "def get_eps_audit(m, r, v, delta, p):\n",
        "    \"\"\"\n",
        "    Calculates a lower bound on eps for a DP audit.\n",
        "\n",
        "    Args:\n",
        "        m: Number of examples, each included independently with probability 0.5.\n",
        "        r: Number of guesses (excluding abstentions).\n",
        "        v: Number of correct guesses by auditor.\n",
        "        delta: DP guarantee of null hypothesis.\n",
        "        p: 1 - confidence (e.g., p = 0.05 corresponds to 95%).\n",
        "\n",
        "    Returns:\n",
        "        eps_min: Lower bound on eps, i.e., algorithm is not (eps, delta)-DP.\n",
        "    \"\"\"\n",
        "    assert 0 \u003c= v \u003c r \u003c= m\n",
        "    assert 0 \u003c= delta \u003c= 1\n",
        "    assert 0 \u003c p \u003c 1\n",
        "\n",
        "    eps_min = 0  # maintain p_value_DP(eps_min) \u003c p\n",
        "    eps_max = 1  # maintain p_value_DP(eps_max) \u003e= p\n",
        "\n",
        "    while p_value_DP_audit(m, r, v, eps_max, delta) \u003c p:\n",
        "        eps_max += 1\n",
        "\n",
        "    for _ in range(30):  # binary search\n",
        "        eps = (eps_min + eps_max) / 2\n",
        "        if p_value_DP_audit(m, r, v, eps, delta) \u003c p:\n",
        "            eps_min = eps\n",
        "        else:\n",
        "            eps_max = eps\n",
        "\n",
        "    return eps_min"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdGAyfGRz90w"
      },
      "outputs": [],
      "source": [
        "#@title Convert observations to scores.\n",
        "\n",
        "# Load in and out canary logits and labels saved from the final evaluation step.\n",
        "in_canary_logits = np.array(input_canary_metrics['incanaryeval_logits_last'])[-1]\n",
        "in_canary_labels = np.array(input_canary_metrics['incanaryeval_labels_last'])[-1]\n",
        "out_canary_logits = np.array(input_canary_metrics['outcanaryeval_logits_last'])[-1]\n",
        "out_canary_labels = np.array(input_canary_metrics['outcanaryeval_labels_last'])[-1]\n",
        "\n",
        "# Convert these into a loss score.\n",
        "in_canary_losses = np.sum(\n",
        "    -jax.nn.log_softmax(in_canary_logits) * in_canary_labels, axis=-1)\n",
        "out_canary_losses = np.sum(\n",
        "    -jax.nn.log_softmax(out_canary_logits) * out_canary_labels, axis=-1)\n",
        "\n",
        "# Convert losses to scores and compute predictions following Algorithm 1 in\n",
        "# https://arxiv.org/abs/2305.08846\n",
        "scores = (\n",
        "    [(float(l), 1) for l in in_canary_losses] +\n",
        "    [(float(l), -1) for l in out_canary_losses]\n",
        "    )\n",
        "sorted_scores = sorted(scores, key=lambda x: x[0])\n",
        "\n",
        "num_pos_guesses = 20 #@param\n",
        "num_neg_guesses = 20 #@param\n",
        "assert num_pos_guesses + num_neg_guesses \u003c= len(sorted_scores)\n",
        "\n",
        "\n",
        "# Compute S and T variables from Algorithm 1 in https://arxiv.org/abs/2305.08846\n",
        "T = (\n",
        "    [1] * num_pos_guesses +\n",
        "    [0] * (len(sorted_scores) - num_pos_guesses - num_neg_guesses) +\n",
        "    [-1] * num_neg_guesses\n",
        ")\n",
        "_, S = zip(*sorted_scores)\n",
        "\n",
        "# Output number of correct guesses.\n",
        "num_correct_guesses = sum([s*t for s, t in zip(S, T)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FeTokp1F0M7N"
      },
      "outputs": [],
      "source": [
        "#@title Output epsilon estimate\n",
        "\n",
        "# p = 1 - confidence\n",
        "p = 0.05 # @param {type:\"slider\", min:0, max:1, step:0.001}\n",
        "\n",
        "eps_lb = get_eps_audit(m=len(sorted_scores),\n",
        "                       r=num_pos_guesses+num_neg_guesses,\n",
        "                       v=num_correct_guesses,\n",
        "                       delta=target_delta, p=p)\n",
        "print(f'Epsilon lower bound: {eps_lb:.3f}')"
      ]
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 0
}
